{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MatchingUsers: this is a test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "from Utils import TransantiagoConstants\n",
    "import EvasionBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "processed_evasion = EvasionBuilder.runCompleteProcess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Processing evasion-ddbb before merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evasion_paradero = processed_evasion[processed_evasion['TP']=='P']\n",
    "evasion_paradero_first = evasion_paradero[evasion_paradero['N_PUERTA']==1]\n",
    "print(type(processed_evasion['SERVICIO'][0])) #should be a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Number of rows in complete evasion database is: ' + str(len(processed_evasion.index)))\n",
    "print('Number of rows in evasion in paradero database is: ' + str(len(evasion_paradero.index)))\n",
    "print('Number of rows in evasion in paradero by first door database is: ' + str(len(evasion_paradero_first.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Filtering dates not in common dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "common_dates = TransantiagoConstants.common_dates\n",
    "common_dates_timestamp = [pd.to_datetime(x) for x in common_dates]\n",
    "common_dates_evasion = evasion_paradero_first[evasion_paradero_first['FECHA'].isin(common_dates_timestamp)]\n",
    "len(common_dates_evasion.index) #Remember to store the number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Filtering for one specific common date (2017-04-11) and analyze it to refactor and debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example = common_dates_evasion[common_dates_evasion['FECHA']==pd.to_datetime('2017-04-11')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(example.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from RunSilentlyDailyEtapasBuilder import RunSilentlyDailyEtapasBuilderClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date = '2017-04-11'\n",
    "etapas_builder = RunSilentlyDailyEtapasBuilderClass(date)\n",
    "processed_sorted_df = etapas_builder.runProcessedProcess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(processed_sorted_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#processed_sorted_df = processed_sorted_df[processed_sorted_df['diferencia_tiempo_secs']<=20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Processing processed_sorted_df before reducing complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "processed_sorted_df['sitio_subida'] = processed_sorted_df['sitio_subida'].str.replace(\"-\", \"\")\n",
    "processed_sorted_df['sitio_subida'] = processed_sorted_df['sitio_subida'].str.replace(\" \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "processed_sorted_df['servicio_subida'] =  processed_sorted_df['servicio_subida'].str.replace('T','')\n",
    "processed_sorted_df['servicio_subida'] =  processed_sorted_df['servicio_subida'].str.split(' ').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trx_servicios = processed_sorted_df['servicio_subida'].unique().tolist()\n",
    "for servicio in trx_servicios:\n",
    "    if 'y' in servicio:\n",
    "        print(servicio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for servicio in trx_servicios:\n",
    "    if 'Y' in servicio:\n",
    "        print(servicio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* First: filter etapas by patentes and servicios surveyed in evasion ddbb so to reduce search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patentes = example['PATENTE'].unique().tolist()\n",
    "servicios = example['SERVICIO'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_sorted_df = processed_sorted_df[(processed_sorted_df['sitio_subida'].isin(patentes))&(processed_sorted_df['servicio_subida'].isin(servicios))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_sorted_df = clean_sorted_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(clean_sorted_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STARTING POINT FOR METHODOLOGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "past_servicio = ''\n",
    "past_patente = ''\n",
    "past_time = pd.to_datetime('')\n",
    "id_exp = 1\n",
    "clean_sorted_df['idExpedicion'] = ''\n",
    "\n",
    "for index,row in clean_sorted_df.iterrows():\n",
    "    actual_servicio = row['servicio_subida']\n",
    "    actual_patente = row['sitio_subida']\n",
    "    actual_time = row['t_subida']\n",
    "    \n",
    "    #THRESHOLD TO CONSIDER A ROW IN A DIFFERENT EXPEDITION IS 15 MINUTES. THIS IS AD-HOC, BUT SHOULD NOT HAVE EFFECT ON FINAL RESULT\n",
    "    if((past_servicio==actual_servicio)&(actual_time - past_time <= (pd.to_datetime('2017-04-11 00:15:00')-pd.to_datetime('2017-04-11 00:00:00')))):\n",
    "        clean_sorted_df.loc[index,'idExpedicion'] = id_exp\n",
    "\n",
    "    elif((past_servicio==actual_servicio)&(actual_time - past_time > (pd.to_datetime('2017-04-11 00:15:00')-pd.to_datetime('2017-04-11 00:00:00')))):\n",
    "        id_exp = id_exp + 1\n",
    "        clean_sorted_df.loc[index,'idExpedicion'] = id_exp\n",
    "        \n",
    "    elif((past_servicio!=actual_servicio)):\n",
    "        id_exp = 1\n",
    "        clean_sorted_df.loc[index,'idExpedicion'] = id_exp\n",
    "        \n",
    "\n",
    "    past_servicio = actual_servicio\n",
    "    past_patente = actual_patente\n",
    "    past_time = actual_time\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_sorted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(clean_sorted_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = {'t_subida':['min', 'max', 'count'], 'diferencia_tiempo_secs':['mean']}\n",
    "grouped_clean_sorted_df = clean_sorted_df.groupby(['sitio_subida','servicio_subida','idExpedicion','par_subida']).agg(f)\n",
    "grouped_clean_sorted_df = grouped_clean_sorted_df.reset_index()\n",
    "grouped_clean_sorted_df.columns = [''.join(col).strip() for col in grouped_clean_sorted_df.columns.values]\n",
    "grouped_clean_sorted_df = grouped_clean_sorted_df.sort_values(by=['sitio_subida', 'servicio_subida', 'idExpedicion', 't_subidamin'], ascending=[True, True, True, True])\n",
    "grouped_clean_sorted_df = grouped_clean_sorted_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grouped_clean_sorted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(grouped_clean_sorted_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "past_plate = '-'\n",
    "past_service = '-'\n",
    "\n",
    "past_par_subida = ['']\n",
    "\n",
    "past_initial_hour = pd.to_datetime('2017-04-11 00:00:00')\n",
    "past_end_hour = pd.to_datetime('2017-04-11 00:00:00')\n",
    "past_id_expedicion = '-'\n",
    "\n",
    "grouped_clean_sorted_df['start_cut']=''\n",
    "grouped_clean_sorted_df['end_cut']=''\n",
    "\n",
    "#from IPython.core.debugger import Tracer\n",
    "\n",
    "for index,row in grouped_clean_sorted_df.iterrows():\n",
    "    \n",
    "    future_index = index+1\n",
    "    \n",
    "    actual_plate = row['sitio_subida']\n",
    "    actual_service = row['servicio_subida']\n",
    "    actual_initial_hour = row['t_subidamin']\n",
    "    actual_end_hour = row['t_subidamax']\n",
    "        \n",
    "    actual_id_expedicion = row['idExpedicion']\n",
    "    \n",
    "    if ((actual_plate!=past_plate)|(actual_service!=past_service)|(actual_id_expedicion!=past_id_expedicion)): #Assuming a pre-defined value, i.e., 30 seconds.\n",
    "        start_cut = actual_initial_hour - (pd.to_datetime('2017-04-11 00:01:00') - pd.to_datetime('2017-04-11 00:00:30'))\n",
    "    else:\n",
    "        start_cut = actual_initial_hour - (actual_initial_hour - past_end_hour)/2\n",
    "    \n",
    "    \n",
    "    if future_index >= len(grouped_clean_sorted_df.index): #We are at the end of the ddff. Assuming a pre-defined value, i.e., 30 seconds \n",
    "        end_cut = actual_end_hour + (pd.to_datetime('2017-04-11 00:01:00') - pd.to_datetime('2017-04-11 00:00:30'))\n",
    "        \n",
    "    else:        \n",
    "        future_plate = grouped_clean_sorted_df.loc[future_index,'sitio_subida']\n",
    "        future_service = grouped_clean_sorted_df.loc[future_index,'servicio_subida']\n",
    "        future_initial_hour = grouped_clean_sorted_df.loc[future_index,'t_subidamin']\n",
    "        future_end_hour = grouped_clean_sorted_df.loc[future_index,'t_subidamax']\n",
    "        future_id_expedicion = grouped_clean_sorted_df.loc[future_index,'idExpedicion']\n",
    "        \n",
    "        if ((actual_plate!=future_plate)|(actual_service!=future_service)|(actual_id_expedicion!=future_id_expedicion)): #Changing service or plate... assuming a pre-defined value, i.e., 30 seconds\n",
    "            end_cut = actual_end_hour + (pd.to_datetime('2017-04-11 00:01:00') - pd.to_datetime('2017-04-11 00:00:30'))\n",
    "        else:\n",
    "            end_cut = actual_end_hour + (future_initial_hour - actual_end_hour)/2\n",
    "   \n",
    "    past_initial_hour = actual_initial_hour\n",
    "    past_end_hour = actual_end_hour\n",
    "    past_id_expedicion = actual_id_expedicion\n",
    "    past_plate = actual_plate\n",
    "    past_service = actual_service\n",
    "    grouped_clean_sorted_df.loc[index,'start_cut']=start_cut\n",
    "    grouped_clean_sorted_df.loc[index,'end_cut']=end_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grouped_clean_sorted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(grouped_clean_sorted_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example = example.reset_index(drop =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index,row in grouped_clean_sorted_df.iterrows():\n",
    "    actual_plate = row['sitio_subida']\n",
    "    actual_service = row['servicio_subida']\n",
    "    start_cut = row['start_cut']\n",
    "    end_cut = row['end_cut']\n",
    "    \n",
    "    actual_util_df = example[(example['PATENTE']==actual_plate)&(example['SERVICIO']==actual_service)&(start_cut<=example['TIEMPO'])&(example['TIEMPO']<=end_cut)]\n",
    "    actual_util_df = actual_util_df[(actual_util_df['INGRESAN'] > actual_util_df['NO_VALIDAN'])] #Be aware of this condition\n",
    "    actual_ev_obs = len(actual_util_df.index) #Mantains order of appearence\n",
    "        \n",
    "    grouped_clean_sorted_df.loc[index,'count_ev_obs'] = actual_ev_obs\n",
    "    grouped_clean_sorted_df.loc[index,'ingresan'] = actual_util_df['INGRESAN'].sum()\n",
    "    grouped_clean_sorted_df.loc[index,'no_validan'] = actual_util_df['NO_VALIDAN'].sum()\n",
    "#    grouped_clean_sorted_df.loc[index,'tiempo_ev'] = actual_util_df['TIEMPO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped_clean_sorted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(grouped_clean_sorted_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "processed_sorted_df[(processed_sorted_df['sitio_subida']=='BJFB62')&(processed_sorted_df['servicio_subida']=='507')&(processed_sorted_df['par_subida']=='T-18-156-OP-40')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped_clean_sorted_df['evasion_rate'] = grouped_clean_sorted_df['no_validan']/grouped_clean_sorted_df['ingresan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped_clean_sorted_df_test = grouped_clean_sorted_df[grouped_clean_sorted_df['diferencia_tiempo_secsmean'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped_clean_sorted_df_test_clean = grouped_clean_sorted_df_test[grouped_clean_sorted_df_test['evasion_rate'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped_clean_sorted_df_test_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torniquetesDataPath = \"C:/Users/leoca_000/Desktop/Evasion/01_analisis/03_datos/03_BUSESTORNIQUETE/Avance_Consolidado_v2.xlsx\"\n",
    "busesTorniquete_df = pd.read_excel(torniquetesDataPath)\n",
    "busesTorniquete_df.columns=['sitio_subida','fecha_instalacion']\n",
    "\n",
    "busesTorniquete_df['sitio_subida'] = busesTorniquete_df['sitio_subida'].str.replace(\"-\", \"\")\n",
    "busesTorniquete_df['sitio_subida'] = busesTorniquete_df['sitio_subida'].str.replace(\" \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "busesTorniquete_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#merged_turnstiles_df = pd.merge(grouped_clean_sorted_df_test_clean,busesTorniquete_df, on='sitio_subida', how='left')\n",
    "#checking_missing = pd.isnull(merged_turnstiles_df['fecha_instalacion'])\n",
    "#print('Not found in turnstile database: ' + str(sum(checking_missing))) #Without turnstiles, then NaT.\n",
    "#merged_turnstiles_df['fecha_instalacion'] = pd.to_datetime(merged_turnstiles_df.fecha_instalacion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#grouped_clean_sorted_df_test_clean_noturns = merged_turnstiles_df[merged_turnstiles_df['fecha_instalacion'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#grouped_clean_sorted_df_test_clean_noturns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig_1, ax_1 = plt.subplots()\n",
    "\n",
    "ax_1.scatter(grouped_clean_sorted_df_test_clean_noturns['diferencia_tiempo_secsmean'],grouped_clean_sorted_df_test_clean_noturns['evasion_rate'])\n",
    "#ax_1.set_title('Evasion vs. Mean Time - No Turns, By Bus and Service, Original')\n",
    "#ax_1.set_xlabel('Mean Time Interval [s]')\n",
    "#ax_1.set_ylabel('Evasion Rate [%]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "* Processing evasion-ddbb before merging\n",
    "\n",
    "evasion_paradero = clean_processed_evasion[clean_processed_evasion['TP']=='P']\n",
    "evasion_paradero_first = evasion_paradero[evasion_paradero['N_PUERTA']==1]\n",
    "print(type(clean_processed_evasion['SERVICIO'][0])) #should be a string\n",
    "\n",
    "print('Number of rows in complete evasion database is: ' + str(len(clean_processed_evasion.index)))\n",
    "print('Number of rows in evasion in paradero database is: ' + str(len(evasion_paradero.index)))\n",
    "print('Number of rows in evasion in paradero by first door database is: ' + str(len(evasion_paradero_first.index)))\n",
    "\n",
    "* Filtering dates not in common dates\n",
    "\n",
    "common_dates = TransantiagoConstants.common_dates\n",
    "common_dates_timestamp = [pd.to_datetime(x) for x in common_dates]\n",
    "common_dates_evasion = evasion_paradero_first[evasion_paradero_first['FECHA'].isin(common_dates_timestamp)]\n",
    "len(common_dates_evasion.index) #Remember to store the number.\n",
    "\n",
    "* <font color='red'>Filtering for one specific common date and analyze it to refactor and debug <- this part should be omitted in the final script. Above methodology is general</font>\n",
    "\n",
    "example = common_dates_evasion[common_dates_evasion['FECHA']==pd.to_datetime('2017-04-11')]\n",
    "\n",
    "len(example.index)\n",
    "\n",
    "from RunSilentlyDailyEtapasBuilder import RunSilentlyDailyEtapasBuilderClass\n",
    "\n",
    "date = '2017-04-11'\n",
    "etapas_builder = RunSilentlyDailyEtapasBuilderClass(date)\n",
    "processed_sorted_df = etapas_builder.runProcessedProcess()\n",
    "\n",
    "len(processed_sorted_df.index)\n",
    "\n",
    "#processed_sorted_df = processed_sorted_df[processed_sorted_df['diferencia_tiempo_secs']<=20]\n",
    "\n",
    "* Processing sorted_df before reducing complexity\n",
    "\n",
    "processed_sorted_df['servicio_subida'] =  processed_sorted_df['servicio_subida'].str.replace('T','')\n",
    "processed_sorted_df['servicio_subida'] =  processed_sorted_df['servicio_subida'].str.split(' ').str[0]\n",
    "\n",
    "processed_sorted_df['sitio_subida'] = processed_sorted_df['sitio_subida'].str.replace(\"-\", \"\")\n",
    "processed_sorted_df['sitio_subida'] = processed_sorted_df['sitio_subida'].str.replace(\" \", \"\")\n",
    "\n",
    "* First: filter etapas by patentes and servicios surveyed in evasion ddbb so to reduce search space\n",
    "\n",
    "patentes = example['PATENTE'].unique()\n",
    "patentes = patentes.tolist()\n",
    "servicios = example['SERVICIO'].unique()\n",
    "servicios = servicios.tolist()\n",
    "\n",
    "clean_sorted_df = processed_sorted_df[(processed_sorted_df['sitio_subida'].isin(patentes))&(processed_sorted_df['servicio_subida'].isin(servicios))]\n",
    "\n",
    "clean_sorted_df = clean_sorted_df.reset_index(drop=True)\n",
    "\n",
    "len(clean_sorted_df.index)\n",
    "\n",
    "* New methodology: appending evasion to trx\n",
    "\n",
    "past_servicio = ''\n",
    "past_patente = ''\n",
    "past_time = pd.to_datetime('')\n",
    "id_exp = 1\n",
    "clean_sorted_df['idExpedicion'] = ''\n",
    "\n",
    "for index,row in clean_sorted_df.iterrows():\n",
    "    actual_servicio = row['servicio_subida']\n",
    "    actual_patente = row['sitio_subida']\n",
    "    actual_time = row['t_subida']\n",
    "    \n",
    "    #SOMETHING\n",
    "    if((past_servicio==actual_servicio)&(actual_time - past_time <= (pd.to_datetime('2017-04-11 00:15:00')-pd.to_datetime('2017-04-11 00:00:00')))):\n",
    "        clean_sorted_df.loc[index,'idExpedicion'] = id_exp\n",
    "\n",
    "    elif((past_servicio==actual_servicio)&(actual_time - past_time > (pd.to_datetime('2017-04-11 00:15:00')-pd.to_datetime('2017-04-11 00:00:00')))):\n",
    "        id_exp = id_exp + 1\n",
    "        clean_sorted_df.loc[index,'idExpedicion'] = id_exp\n",
    "        \n",
    "    elif((past_servicio!=actual_servicio)):\n",
    "        id_exp = 1\n",
    "        clean_sorted_df.loc[index,'idExpedicion'] = id_exp\n",
    "        \n",
    "\n",
    "    past_servicio = actual_servicio\n",
    "    past_patente = actual_patente\n",
    "    past_time = actual_time\n",
    "    \n",
    "\n",
    "clean_sorted_df.head()\n",
    "\n",
    "f = {'t_subida':['min', 'max', 'count'], 'diferencia_tiempo_secs':['mean']}\n",
    "grouped_clean_sorted_df = clean_sorted_df.groupby(['sitio_subida','servicio_subida','idExpedicion','par_subida']).agg(f)\n",
    "grouped_clean_sorted_df = grouped_clean_sorted_df.reset_index()\n",
    "grouped_clean_sorted_df.columns = [''.join(col).strip() for col in grouped_clean_sorted_df.columns.values]\n",
    "grouped_clean_sorted_df = grouped_clean_sorted_df.sort_values(by=['sitio_subida', 'servicio_subida', 'idExpedicion', 't_subidamin'], ascending=[True, True, True, True])\n",
    "grouped_clean_sorted_df = grouped_clean_sorted_df.reset_index(drop=True)\n",
    "\n",
    "i = 0\n",
    "past_plate = '-'\n",
    "past_service = '-'\n",
    "\n",
    "past_par_subida = ['']\n",
    "\n",
    "past_initial_hour = pd.to_datetime('2017-04-11 00:00:00')\n",
    "past_end_hour = pd.to_datetime('2017-04-11 00:00:00')\n",
    "past_id_expedicion = '-'\n",
    "\n",
    "grouped_clean_sorted_df['start_cut']=''\n",
    "grouped_clean_sorted_df['end_cut']=''\n",
    "\n",
    "from IPython.core.debugger import Tracer\n",
    "\n",
    "for index,row in grouped_clean_sorted_df.iterrows():\n",
    "    \n",
    "    future_index = index+1\n",
    "    \n",
    "    actual_plate = row['sitio_subida']\n",
    "    actual_service = row['servicio_subida']\n",
    "    actual_initial_hour = row['t_subidamin']\n",
    "    actual_end_hour = row['t_subidamax']\n",
    "        \n",
    "    actual_id_expedicion = row['idExpedicion']\n",
    "    \n",
    "    if ((actual_plate!=past_plate)|(actual_service!=past_service)|(actual_id_expedicion!=past_id_expedicion)): #Assuming a pre-defined value, i.e., 30 seconds.\n",
    "        start_cut = actual_initial_hour - (pd.to_datetime('2017-04-11 00:01:00') - pd.to_datetime('2017-04-11 00:00:30'))\n",
    "    else:\n",
    "        start_cut = actual_initial_hour - (actual_initial_hour - past_end_hour)/2\n",
    "    \n",
    "    \n",
    "    if future_index >= len(grouped_clean_sorted_df.index): #We are at the end of the ddff. Assuming a pre-defined value, i.e., 30 seconds \n",
    "        end_cut = actual_end_hour + (pd.to_datetime('2017-04-11 00:01:00') - pd.to_datetime('2017-04-11 00:00:30'))\n",
    "        \n",
    "    else:        \n",
    "        future_plate = grouped_clean_sorted_df.loc[future_index,'sitio_subida']\n",
    "        future_service = grouped_clean_sorted_df.loc[future_index,'servicio_subida']\n",
    "        future_initial_hour = grouped_clean_sorted_df.loc[future_index,'t_subidamin']\n",
    "        future_end_hour = grouped_clean_sorted_df.loc[future_index,'t_subidamax']\n",
    "        future_id_expedicion = grouped_clean_sorted_df.loc[future_index,'idExpedicion']\n",
    "        \n",
    "        if ((actual_plate!=future_plate)|(actual_service!=future_service)|(actual_id_expedicion!=future_id_expedicion)): #Changing service or plate... assuming a pre-defined value, i.e., 30 seconds\n",
    "            end_cut = actual_end_hour + (pd.to_datetime('2017-04-11 00:01:00') - pd.to_datetime('2017-04-11 00:00:30'))\n",
    "        else:\n",
    "            end_cut = actual_end_hour + (future_initial_hour - actual_end_hour)/2\n",
    "   \n",
    "    past_initial_hour = actual_initial_hour\n",
    "    past_end_hour = actual_end_hour\n",
    "    past_id_expedicion = actual_id_expedicion\n",
    "    past_plate = actual_plate\n",
    "    past_service = actual_service\n",
    "    grouped_clean_sorted_df.loc[index,'start_cut']=start_cut\n",
    "    grouped_clean_sorted_df.loc[index,'end_cut']=end_cut\n",
    "\n",
    "example.loc[:,'TIEMPO'] = example.loc[:,'FECHA'].dt.strftime('%Y-%m-%d') + ' ' + example.loc[:,'TIEMPO']\n",
    "example['TIEMPO'] = pd.to_datetime(example['TIEMPO'])\n",
    "\n",
    "example = example.reset_index(drop =True)\n",
    "\n",
    "for index,row in grouped_clean_sorted_df.iterrows():\n",
    "    actual_plate = row['sitio_subida']\n",
    "    actual_service = row['servicio_subida']\n",
    "    start_cut = row['start_cut']\n",
    "    end_cut = row['end_cut']\n",
    "    \n",
    "    actual_util_df = example[(example['PATENTE']==actual_plate)&(example['SERVICIO']==actual_service)&(start_cut<=example['TIEMPO'])&(example['TIEMPO']<=end_cut)]\n",
    "    actual_util_df = actual_util_df[(actual_util_df['INGRESAN'] > actual_util_df['NO_VALIDAN'])] #Be aware of this condition\n",
    "    actual_ev_obs = len(actual_util_df.index) #Mantains order of appearence\n",
    "        \n",
    "    grouped_clean_sorted_df.loc[index,'count_ev_obs'] = actual_ev_obs\n",
    "    grouped_clean_sorted_df.loc[index,'ingresan'] = actual_util_df['INGRESAN'].sum()\n",
    "    grouped_clean_sorted_df.loc[index,'no_validan'] = actual_util_df['NO_VALIDAN'].sum()\n",
    "#    grouped_clean_sorted_df.loc[index,'tiempo_ev'] = actual_util_df['TIEMPO']\n",
    "\n",
    "grouped_clean_sorted_df.head()\n",
    "\n",
    "len(grouped_clean_sorted_df.index)\n",
    "\n",
    "processed_sorted_df[(processed_sorted_df['sitio_subida']=='BJFB62')&(processed_sorted_df['servicio_subida']=='507')&(processed_sorted_df['par_subida']=='T-18-156-OP-40')]\n",
    "\n",
    "grouped_clean_sorted_df['evasion_rate'] = grouped_clean_sorted_df['no_validan']/grouped_clean_sorted_df['ingresan']\n",
    "\n",
    "grouped_clean_sorted_df_test = grouped_clean_sorted_df[grouped_clean_sorted_df['diferencia_tiempo_secsmean'].notnull()]\n",
    "\n",
    "grouped_clean_sorted_df_test_clean = grouped_clean_sorted_df_test[grouped_clean_sorted_df_test['evasion_rate'].notnull()]\n",
    "\n",
    "grouped_clean_sorted_df_test_clean.head()\n",
    "\n",
    "torniquetesDataPath = \"C:/Users/leoca_000/Desktop/Evasion/01_analisis/03_datos/03_BUSESTORNIQUETE/Avance_Consolidado_v2.xlsx\"\n",
    "busesTorniquete_df = pd.read_excel(torniquetesDataPath)\n",
    "busesTorniquete_df.columns=['sitio_subida','fecha_instalacion']\n",
    "\n",
    "busesTorniquete_df['sitio_subida'] = busesTorniquete_df['sitio_subida'].str.replace(\"-\", \"\")\n",
    "busesTorniquete_df['sitio_subida'] = busesTorniquete_df['sitio_subida'].str.replace(\" \", \"\")\n",
    "\n",
    "busesTorniquete_df.head()\n",
    "\n",
    "#merged_turnstiles_df = pd.merge(grouped_clean_sorted_df_test_clean,busesTorniquete_df, on='sitio_subida', how='left')\n",
    "#checking_missing = pd.isnull(merged_turnstiles_df['fecha_instalacion'])\n",
    "#print('Not found in turnstile database: ' + str(sum(checking_missing))) #Without turnstiles, then NaT.\n",
    "#merged_turnstiles_df['fecha_instalacion'] = pd.to_datetime(merged_turnstiles_df.fecha_instalacion)\n",
    "\n",
    "#grouped_clean_sorted_df_test_clean_noturns = merged_turnstiles_df[merged_turnstiles_df['fecha_instalacion'].isnull()]\n",
    "\n",
    "#grouped_clean_sorted_df_test_clean_noturns.head()\n",
    "\n",
    "fig_1, ax_1 = plt.subplots()\n",
    "\n",
    "ax_1.scatter(grouped_clean_sorted_df_test_clean_noturns['diferencia_tiempo_secsmean'],grouped_clean_sorted_df_test_clean_noturns['evasion_rate'])\n",
    "#ax_1.set_title('Evasion vs. Mean Time - No Turns, By Bus and Service, Original')\n",
    "#ax_1.set_xlabel('Mean Time Interval [s]')\n",
    "#ax_1.set_ylabel('Evasion Rate [%]')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
