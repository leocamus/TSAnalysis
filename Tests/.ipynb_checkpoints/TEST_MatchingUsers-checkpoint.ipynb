{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MatchingUsers: this is a test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST 1: Check if MatchingUsers.py produce same result as jupyter prototype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "from Utils import TransantiagoConstants\n",
    "import EvasionBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_evasion = EvasionBuilder.runCompleteProcess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Processing evasion-ddbb before merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evasion_paradero = processed_evasion[processed_evasion['TP']=='P']\n",
    "evasion_paradero_first = evasion_paradero[evasion_paradero['N_PUERTA']==1]\n",
    "print(type(processed_evasion['SERVICIO'][0])) #should be a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of rows in complete evasion database is: ' + str(len(processed_evasion.index)))\n",
    "print('Number of rows in evasion in paradero database is: ' + str(len(evasion_paradero.index)))\n",
    "print('Number of rows in evasion in paradero by first door database is: ' + str(len(evasion_paradero_first.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Filtering dates not in common dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_dates = TransantiagoConstants.common_dates\n",
    "common_dates_timestamp = [pd.to_datetime(x) for x in common_dates]\n",
    "common_dates_evasion = evasion_paradero_first[evasion_paradero_first['FECHA'].isin(common_dates_timestamp)]\n",
    "print('The number of rows in the common_dates evasion database is: ' + str(len(common_dates_evasion.index)) + ' rows.') #Remember to store the number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Filtering for one specific common date (2017-04-11) and analyze it to refactor and debug.\n",
    "* The result from the above process should be used to test MatchingUsers.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = common_dates_evasion[common_dates_evasion['FECHA']==pd.to_datetime('2017-04-11')]\n",
    "print('The number of rows in the example-evasion database is: ' + str(len(example.index)) + ' rows.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from RunSilentlyDailyEtapasBuilder import RunSilentlyDailyEtapasBuilderClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '2017-04-11'\n",
    "etapas_builder = RunSilentlyDailyEtapasBuilderClass(date)\n",
    "processed_sorted_df = etapas_builder.runProcessedProcess()\n",
    "\n",
    "print('The number of rows in the original etapas database is: ' + str(len(processed_sorted_df.index)) + ' rows.' )\n",
    "#Filtering special cases.\n",
    "filtered_processed_sorted_df = processed_sorted_df[(processed_sorted_df['diferencia_tiempo_secs']<=20)|(processed_sorted_df['diferencia_tiempo_secs'].isnull())]\n",
    "print('The number of rows in the filtered (by special cases) etapas database is: '  + str(len(filtered_processed_sorted_df.index)) + ' rows.' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Processing filtered_processed_sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_processed_sorted_df.loc[:,'sitio_subida'] = filtered_processed_sorted_df.loc[:,'sitio_subida'].str.replace(\"-\", \"\")\n",
    "filtered_processed_sorted_df.loc[:,'sitio_subida'] = filtered_processed_sorted_df.loc[:,'sitio_subida'].str.replace(\" \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_processed_sorted_df.loc[:,'servicio_subida'] =  filtered_processed_sorted_df.loc[:,'servicio_subida'].str.replace('T','')\n",
    "filtered_processed_sorted_df.loc[:,'servicio_subida'] =  filtered_processed_sorted_df.loc[:,'servicio_subida'].str.split(' ').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patentes = example['PATENTE'].unique().tolist()\n",
    "servicios = example['SERVICIO'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_sorted_df = filtered_processed_sorted_df[(filtered_processed_sorted_df['sitio_subida'].isin(patentes))&(filtered_processed_sorted_df['servicio_subida'].isin(servicios))]\n",
    "clean_sorted_df = clean_sorted_df.reset_index(drop=True)\n",
    "print('The number of rows in the filtered_processed_sorted_df filtered by patentes and servicios surveyed in a particular date is: ' + str(len(clean_sorted_df.index)) + ' rows.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### METHODOLOGY STARTS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Appending idExpedicion based on some ad-hoc condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "past_servicio = ''\n",
    "past_patente = ''\n",
    "past_time = pd.to_datetime('')\n",
    "id_exp = 1\n",
    "clean_sorted_df['idExpedicion'] = ''\n",
    "\n",
    "for index,row in clean_sorted_df.iterrows():\n",
    "    actual_servicio = row['servicio_subida']\n",
    "    actual_patente = row['sitio_subida']\n",
    "    actual_time = row['t_subida']\n",
    "    \n",
    "    #THRESHOLD TO CONSIDER A ROW IN A DIFFERENT EXPEDITION IS 15 MINUTES. THIS IS AD-HOC, BUT SHOULD NOT HAVE EFFECT ON FINAL RESULT\n",
    "    if((past_servicio==actual_servicio)&(actual_time - past_time <= pd.Timedelta('15 minutes'))):\n",
    "        clean_sorted_df.loc[index,'idExpedicion'] = id_exp\n",
    "\n",
    "    elif((past_servicio==actual_servicio)&(actual_time - past_time > pd.Timedelta('15 minutes'))):\n",
    "        id_exp = id_exp + 1\n",
    "        clean_sorted_df.loc[index,'idExpedicion'] = id_exp\n",
    "        \n",
    "    elif((past_servicio!=actual_servicio)):\n",
    "        id_exp = 1\n",
    "        clean_sorted_df.loc[index,'idExpedicion'] = id_exp\n",
    "        \n",
    "    past_servicio = actual_servicio\n",
    "    past_patente = actual_patente\n",
    "    past_time = actual_time\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The number of rows in clean_sorted_df is: ' + str(len(clean_sorted_df.index)) + ' rows.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Grouping by bus-service-idExp-stop. <strong> This is a critical step </strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = {'t_subida':['min', 'max', 'count'], 'diferencia_tiempo_secs':['mean']}\n",
    "grouped_clean_sorted_df = clean_sorted_df.groupby(['sitio_subida','servicio_subida','idExpedicion','par_subida']).agg(f)\n",
    "grouped_clean_sorted_df = grouped_clean_sorted_df.reset_index()\n",
    "\n",
    "columns = []\n",
    "for col in grouped_clean_sorted_df.columns.values:\n",
    "    if col[1]!='':\n",
    "        col = '_'.join(col).strip()\n",
    "    else:\n",
    "        col = ''.join(col).strip()\n",
    "    columns.append(col)\n",
    "\n",
    "grouped_clean_sorted_df.columns = columns\n",
    "\n",
    "grouped_clean_sorted_df = grouped_clean_sorted_df.sort_values(by=['sitio_subida', 'servicio_subida', 'idExpedicion', 't_subida_min'], ascending=[True, True, True, True])\n",
    "grouped_clean_sorted_df = grouped_clean_sorted_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The number of rows in the grouped_clean_sorted_df is: ' + str(len(grouped_clean_sorted_df.index)) + ' rows.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Computing and appending start and end cuts to search in evasion database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "past_plate = '-'\n",
    "past_service = '-'\n",
    "\n",
    "past_par_subida = ['']\n",
    "\n",
    "past_initial_hour = pd.to_datetime('2017-04-11 00:00:00')\n",
    "past_end_hour = pd.to_datetime('2017-04-11 00:00:00')\n",
    "past_id_expedicion = '-'\n",
    "\n",
    "grouped_clean_sorted_df['start_cut']=''\n",
    "grouped_clean_sorted_df['end_cut']=''\n",
    "\n",
    "#from IPython.core.debugger import Tracer\n",
    "\n",
    "for index,row in grouped_clean_sorted_df.iterrows():\n",
    "    \n",
    "    future_index = index+1\n",
    "    \n",
    "    actual_plate = row['sitio_subida']\n",
    "    actual_service = row['servicio_subida']\n",
    "    actual_initial_hour = row['t_subida_min']\n",
    "    actual_end_hour = row['t_subida_max']\n",
    "        \n",
    "    actual_id_expedicion = row['idExpedicion']\n",
    "    \n",
    "    if ((actual_plate!=past_plate)|(actual_service!=past_service)|(actual_id_expedicion!=past_id_expedicion)): #Assuming a pre-defined value, i.e., 30 seconds.\n",
    "        start_cut = actual_initial_hour - pd.Timedelta('30 seconds')\n",
    "    else:\n",
    "        start_cut = actual_initial_hour - (actual_initial_hour - past_end_hour)/2\n",
    "    \n",
    "    \n",
    "    if future_index >= len(grouped_clean_sorted_df.index): #We are at the end of the ddff. Assuming a pre-defined value, i.e., 30 seconds \n",
    "        end_cut = actual_end_hour + pd.Timedelta('30 seconds')\n",
    "        \n",
    "    else:        \n",
    "        future_plate = grouped_clean_sorted_df.loc[future_index,'sitio_subida']\n",
    "        future_service = grouped_clean_sorted_df.loc[future_index,'servicio_subida']\n",
    "        future_initial_hour = grouped_clean_sorted_df.loc[future_index,'t_subida_min']\n",
    "        future_end_hour = grouped_clean_sorted_df.loc[future_index,'t_subida_max']\n",
    "        future_id_expedicion = grouped_clean_sorted_df.loc[future_index,'idExpedicion']\n",
    "        \n",
    "        if ((actual_plate!=future_plate)|(actual_service!=future_service)|(actual_id_expedicion!=future_id_expedicion)): #Changing service or plate... assuming a pre-defined value, i.e., 30 seconds\n",
    "            end_cut = actual_end_hour + pd.Timedelta('30 seconds')\n",
    "        else:\n",
    "            end_cut = actual_end_hour + (future_initial_hour - actual_end_hour)/2\n",
    "   \n",
    "    past_initial_hour = actual_initial_hour\n",
    "    past_end_hour = actual_end_hour\n",
    "    past_id_expedicion = actual_id_expedicion\n",
    "    past_plate = actual_plate\n",
    "    past_service = actual_service\n",
    "    grouped_clean_sorted_df.loc[index,'start_cut']=start_cut\n",
    "    grouped_clean_sorted_df.loc[index,'end_cut']=end_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grouped_clean_sorted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The number of rows in the grouped_clean_sorted_df is: ' + str(len(grouped_clean_sorted_df.index)) + ' rows.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Finally, slicing evasion database and appending util information about boardings and not paying users to grouped_clean_sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index,row in grouped_clean_sorted_df.iterrows():\n",
    "    actual_plate = row['sitio_subida']\n",
    "    actual_service = row['servicio_subida']\n",
    "    start_cut = row['start_cut']\n",
    "    end_cut = row['end_cut']\n",
    "    \n",
    "    actual_util_df = example[(example['PATENTE']==actual_plate)&(example['SERVICIO']==actual_service)&(start_cut<=example['TIEMPO'])&(example['TIEMPO']<=end_cut)]\n",
    "    actual_util_df = actual_util_df[(actual_util_df['INGRESAN'] > actual_util_df['NO_VALIDAN'])] #Be aware of this condition\n",
    "    actual_ev_obs = len(actual_util_df.index)\n",
    "        \n",
    "    grouped_clean_sorted_df.loc[index,'EVASION_COUNT'] = actual_ev_obs\n",
    "    grouped_clean_sorted_df.loc[index,'TOTAL_INGRESAN'] = actual_util_df['INGRESAN'].sum()\n",
    "    grouped_clean_sorted_df.loc[index,'TOTAL_NO_VALIDAN'] = actual_util_df['NO_VALIDAN'].sum()\n",
    "#    grouped_clean_sorted_df.loc[index,'tiempo_ev'] = actual_util_df['TIEMPO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The number of rows in the grouped_clean_sorted_df is: ' + str(len(grouped_clean_sorted_df.index)) + ' rows.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Re-appending 'fecha_instalacion' attribute since groupby operation deleted it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torniquetesDataPath = TransantiagoConstants.busesTorniqueteDir + '/Avance_Consolidado_v2.xlsx'\n",
    "busesTorniquete_df = pd.read_excel(torniquetesDataPath)\n",
    "busesTorniquete_df.columns=['sitio_subida','fecha_instalacion']\n",
    "\n",
    "busesTorniquete_df['sitio_subida'] = busesTorniquete_df['sitio_subida'].str.replace(\"-\", \"\")\n",
    "busesTorniquete_df['sitio_subida'] = busesTorniquete_df['sitio_subida'].str.replace(\" \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_grouped_clean_sorted_df = pd.merge(grouped_clean_sorted_df,busesTorniquete_df, on='sitio_subida', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The number of rows in the grouped_clean_sorted_df is: ' + str(len(merged_grouped_clean_sorted_df.index)) + ' rows.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged_grouped_clean_sorted_df.loc[:,'SI_TORNIQUETE'] = (merged_grouped_clean_sorted_df.loc[:,'fecha_instalacion'].notnull())\n",
    "merged_grouped_clean_sorted_df.loc[:,'SI_2017_TORNIQUETE'] = (merged_grouped_clean_sorted_df.loc[:,'fecha_instalacion']>pd.to_datetime('2017-01-01'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### METHODOLOGY ENDS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A quick analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_grouped_clean_sorted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged_grouped_clean_sorted_df.loc[:,'EVASION_RATE'] = merged_grouped_clean_sorted_df.loc[:,'TOTAL_NO_VALIDAN']/merged_grouped_clean_sorted_df.loc[:,'TOTAL_INGRESAN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = merged_grouped_clean_sorted_df[merged_grouped_clean_sorted_df['diferencia_tiempo_secs_mean'].notnull()]\n",
    "test_2 = test[test['EVASION_COUNT']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_2_no_turns = test_2[(test_2['SI_TORNIQUETE']==False)|((test_2['SI_TORNIQUETE']==True) & (test_2['t_subida_max']<=test_2['fecha_instalacion']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_1, ax_1 = plt.subplots()\n",
    "\n",
    "ax_1.scatter(test_2_no_turns['diferencia_tiempo_secs_mean'],test_2_no_turns['EVASION_RATE'])\n",
    "ax_1.set_title('Evasion vs. Mean Time - No Turns, By Bus-Service-Stop, Original')\n",
    "ax_1.set_xlabel('Mean Time Interval [s]')\n",
    "ax_1.set_ylabel('Evasion Rate [%]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
