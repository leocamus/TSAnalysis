{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "import datetime as dt\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "import EvasionBuilder\n",
    "from Utils import TransantiagoConstants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Building complete evasion database via EvasionBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The only non-matched user_code services are: \n",
      "D06\n",
      "Number of duplicated rows in complete evasion database is: 6362\n",
      "Number of collapsed-duplicated rows in complete evasion database is: 3175\n",
      "Number of rows in complete evasion database without duplicated rows at all is: 93060\n",
      "Final number of rows in complete evasion database with collapsed duplicated rows is: 96235\n"
     ]
    }
   ],
   "source": [
    "[first_q, second_q, third_q] = EvasionBuilder.loadSinglesEvasion()\n",
    "\n",
    "complete_evasion = EvasionBuilder.processSinglesEvasiondAndConcat(first_q,second_q,third_q)\n",
    "\n",
    "complete_evasion_w_codes = EvasionBuilder.mergeTransantiagoCodes(complete_evasion)\n",
    "\n",
    "processed_evasion = EvasionBuilder.processCompleteEvasionDataFrame(complete_evasion_w_codes)\n",
    "\n",
    "clean_processed_evasion = EvasionBuilder.deleteDuplicatedInCompleteEvasion(processed_evasion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Processing complete evasion database depending on necessity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evasion_paradero = clean_processed_evasion[clean_processed_evasion['TP']=='P']\n",
    "evasion_paradero_first = evasion_paradero[evasion_paradero['N_PUERTA']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in complete evasion database is: 96235\n",
      "Number of rows in evasion in paradero database is: 94531\n",
      "Number of rows in evasion in paradero by first door database is: 33755\n"
     ]
    }
   ],
   "source": [
    "print('Number of rows in complete evasion database is: ' + str(len(clean_processed_evasion.index)))\n",
    "print('Number of rows in evasion in paradero database is: ' + str(len(evasion_paradero.index)))\n",
    "print('Number of rows in evasion in paradero by first door database is: ' + str(len(evasion_paradero_first.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Filtering dates not in common dates. DataFrame \"common_dates_evasion\" will be the final evasion DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in complete evasion database filtered by common_dates is: 14756\n"
     ]
    }
   ],
   "source": [
    "common_dates = TransantiagoConstants.common_dates\n",
    "common_dates_timestamp = [pd.to_datetime(x) for x in common_dates]\n",
    "common_dates_evasion = evasion_paradero_first[evasion_paradero_first['FECHA'].isin(common_dates_timestamp)]\n",
    "\n",
    "print('Number of rows in complete evasion database filtered by common_dates is: ' + str(len(common_dates_evasion.index))) #Remember to store the number.\n",
    "\n",
    "common_dates_evasion.loc[:,'TIEMPO'] = common_dates_evasion.loc[:,'FECHA'].dt.strftime('%Y-%m-%d') + ' ' + common_dates_evasion.loc[:,'TIEMPO']\n",
    "common_dates_evasion.loc[:,'TIEMPO'] = pd.to_datetime(common_dates_evasion.loc[:,'TIEMPO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_dates_evasion = common_dates_evasion.sort_values(by=['PATENTE', 'SERVICIO', 'TIEMPO'], ascending=[True, True, True])\n",
    "common_dates_evasion = common_dates_evasion.reset_index(drop =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patentes = common_dates_evasion['PATENTE'].unique()\n",
    "patentes = patentes.tolist()\n",
    "servicios = common_dates_evasion['SERVICIO'].unique()\n",
    "servicios = servicios.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Building Etapas DataBase via RunSilentlyDailyEtapasBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_dates = common_dates[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from RunSilentlyDailyEtapasBuilder import RunSilentlyDailyEtapasBuilderClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for date in common_dates:\n",
    "    \n",
    "    etapas_builder = RunSilentlyDailyEtapasBuilderClass(date)\n",
    "    processed_sorted_df = etapas_builder.runProcessedProcess()\n",
    "#    processed_sorted_df = processed_sorted_df[processed_sorted_df['diferencia_tiempo_secs']<=20] <- BE AWARE OF THIS LINE...\n",
    "    processed_sorted_df['sitio_subida'] = processed_sorted_df['sitio_subida'].str.replace(\"-\", \"\")\n",
    "    processed_sorted_df['sitio_subida'] = processed_sorted_df['sitio_subida'].str.replace(\" \", \"\")\n",
    "    processed_sorted_df['servicio_subida'] =  processed_sorted_df['servicio_subida'].str.replace('T','')\n",
    "    processed_sorted_df['servicio_subida'] =  processed_sorted_df['servicio_subida'].str.split(' ').str[0]\n",
    "    clean_sorted_df = processed_sorted_df[(processed_sorted_df['sitio_subida'].isin(patentes))&(processed_sorted_df['servicio_subida'].isin(servicios))]\n",
    "    clean_sorted_df = clean_sorted_df.reset_index(drop=True)\n",
    "    \n",
    "    past_servicio = ''\n",
    "    past_patente = ''\n",
    "    past_time = pd.to_datetime('')\n",
    "    id_exp = 1\n",
    "    clean_sorted_df['idExpedicion'] = ''\n",
    "\n",
    "    # 1 - appending idExpedicion built ad-hoc #\n",
    "    for index,row in clean_sorted_df.iterrows():\n",
    "        actual_servicio = row['servicio_subida']\n",
    "        actual_patente = row['sitio_subida']\n",
    "        actual_time = row['t_subida']\n",
    "\n",
    "        #SOMETHING\n",
    "        if((past_servicio==actual_servicio)&(actual_time - past_time <= (pd.to_datetime('2017-04-11 00:15:00')-pd.to_datetime('2017-04-11 00:00:00')))):\n",
    "            clean_sorted_df.loc[index,'idExpedicion'] = id_exp\n",
    "\n",
    "        elif((past_servicio==actual_servicio)&(actual_time - past_time > (pd.to_datetime('2017-04-11 00:15:00')-pd.to_datetime('2017-04-11 00:00:00')))):\n",
    "            id_exp = id_exp + 1\n",
    "            clean_sorted_df.loc[index,'idExpedicion'] = id_exp\n",
    "\n",
    "        elif((past_servicio!=actual_servicio)):\n",
    "            id_exp = 1\n",
    "            clean_sorted_df.loc[index,'idExpedicion'] = id_exp\n",
    "\n",
    "\n",
    "        past_servicio = actual_servicio\n",
    "        past_patente = actual_patente\n",
    "        past_time = actual_time\n",
    "    \n",
    "    f = {'t_subida':['min', 'max', 'count'], 'diferencia_tiempo_secs':['mean']}\n",
    "    grouped_clean_sorted_df = clean_sorted_df.groupby(['sitio_subida','servicio_subida','idExpedicion','par_subida']).agg(f)\n",
    "    grouped_clean_sorted_df = grouped_clean_sorted_df.reset_index()\n",
    "    grouped_clean_sorted_df.columns = [''.join(col).strip() for col in grouped_clean_sorted_df.columns.values]\n",
    "    grouped_clean_sorted_df = grouped_clean_sorted_df.sort_values(by=['sitio_subida', 'servicio_subida', 'idExpedicion', 't_subidamin'], ascending=[True, True, True, True])\n",
    "    grouped_clean_sorted_df = grouped_clean_sorted_df.reset_index(drop=True)\n",
    "    \n",
    "    past_plate = '-'\n",
    "    past_service = '-'\n",
    "    past_par_subida = ['']\n",
    "    past_initial_hour = pd.to_datetime('2017-04-11 00:00:00')\n",
    "    past_end_hour = pd.to_datetime('2017-04-11 00:00:00')\n",
    "    past_id_expedicion = '-'\n",
    "\n",
    "    grouped_clean_sorted_df['start_cut']=''\n",
    "    grouped_clean_sorted_df['end_cut']=''\n",
    "\n",
    "    for index,row in grouped_clean_sorted_df.iterrows():\n",
    "\n",
    "        future_index = index+1\n",
    "\n",
    "        actual_plate = row['sitio_subida']\n",
    "        actual_service = row['servicio_subida']\n",
    "        actual_initial_hour = row['t_subidamin']\n",
    "        actual_end_hour = row['t_subidamax']\n",
    "\n",
    "        actual_id_expedicion = row['idExpedicion']\n",
    "\n",
    "        if ((actual_plate!=past_plate)|(actual_service!=past_service)|(actual_id_expedicion!=past_id_expedicion)): #Assuming a pre-defined value, i.e., 30 seconds.\n",
    "            start_cut = actual_initial_hour - (pd.to_datetime('2017-04-11 00:01:00') - pd.to_datetime('2017-04-11 00:00:30'))\n",
    "        else:\n",
    "            start_cut = actual_initial_hour - (actual_initial_hour - past_end_hour)/2\n",
    "\n",
    "\n",
    "        if future_index >= len(grouped_clean_sorted_df.index): #We are at the end of the ddff. Assuming a pre-defined value, i.e., 30 seconds \n",
    "            end_cut = actual_end_hour + (pd.to_datetime('2017-04-11 00:01:00') - pd.to_datetime('2017-04-11 00:00:30'))\n",
    "\n",
    "        else:        \n",
    "            future_plate = grouped_clean_sorted_df.loc[future_index,'sitio_subida']\n",
    "            future_service = grouped_clean_sorted_df.loc[future_index,'servicio_subida']\n",
    "            future_initial_hour = grouped_clean_sorted_df.loc[future_index,'t_subidamin']\n",
    "            future_end_hour = grouped_clean_sorted_df.loc[future_index,'t_subidamax']\n",
    "            future_id_expedicion = grouped_clean_sorted_df.loc[future_index,'idExpedicion']\n",
    "\n",
    "            if ((actual_plate!=future_plate)|(actual_service!=future_service)|(actual_id_expedicion!=future_id_expedicion)): #Changing service or plate... assuming a pre-defined value, i.e., 30 seconds\n",
    "                end_cut = actual_end_hour + (pd.to_datetime('2017-04-11 00:01:00') - pd.to_datetime('2017-04-11 00:00:30'))\n",
    "            else:\n",
    "                end_cut = actual_end_hour + (future_initial_hour - actual_end_hour)/2\n",
    "\n",
    "        past_initial_hour = actual_initial_hour\n",
    "        past_end_hour = actual_end_hour\n",
    "        past_id_expedicion = actual_id_expedicion\n",
    "        past_plate = actual_plate\n",
    "        past_service = actual_service\n",
    "        grouped_clean_sorted_df.loc[index,'start_cut']=start_cut\n",
    "        grouped_clean_sorted_df.loc[index,'end_cut']=end_cut\n",
    "\n",
    "    for index,row in grouped_clean_sorted_df.iterrows():\n",
    "        actual_plate = row['sitio_subida']\n",
    "        actual_service = row['servicio_subida']\n",
    "        start_cut = row['start_cut']\n",
    "        end_cut = row['end_cut']\n",
    "\n",
    "        actual_util_df = example[(example['PATENTE']==actual_plate)&(example['SERVICIO']==actual_service)&(start_cut<=example['TIEMPO'])&(example['TIEMPO']<=end_cut)]\n",
    "        actual_util_df = actual_util_df[(actual_util_df['INGRESAN'] > actual_util_df['NO_VALIDAN'])] #Be aware of this condition\n",
    "        actual_ev_obs = len(actual_util_df.index) #Mantains order of appearence\n",
    "\n",
    "        grouped_clean_sorted_df.loc[index,'count_ev_obs'] = actual_ev_obs\n",
    "        grouped_clean_sorted_df.loc[index,'ingresan'] = actual_util_df['INGRESAN'].sum()\n",
    "        grouped_clean_sorted_df.loc[index,'no_validan'] = actual_util_df['NO_VALIDAN'].sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
