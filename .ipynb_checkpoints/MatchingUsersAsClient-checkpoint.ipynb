{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "import datetime as dt\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "import EvasionBuilder\n",
    "from Utils import TransantiagoConstants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Building complete evasion database via EvasionBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The only non-matched user_code services are: \n",
      "D06\n",
      "Number of duplicated rows in complete evasion database is: 6362\n",
      "Number of collapsed-duplicated rows in complete evasion database is: 3175\n",
      "Number of rows in complete evasion database without duplicated rows at all is: 93060\n",
      "Final number of rows in complete evasion database with collapsed duplicated rows is: 96235\n"
     ]
    }
   ],
   "source": [
    "[first_q, second_q, third_q] = EvasionBuilder.loadSinglesEvasion()\n",
    "\n",
    "complete_evasion = EvasionBuilder.processSinglesEvasiondAndConcat(first_q,second_q,third_q)\n",
    "\n",
    "complete_evasion_w_codes = EvasionBuilder.mergeTransantiagoCodes(complete_evasion)\n",
    "\n",
    "processed_evasion = EvasionBuilder.processCompleteEvasionDataFrame(complete_evasion_w_codes)\n",
    "\n",
    "clean_processed_evasion = EvasionBuilder.deleteDuplicatedInCompleteEvasion(processed_evasion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Processing complete evasion database depending on necessity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evasion_paradero = clean_processed_evasion[clean_processed_evasion['TP']=='P']\n",
    "evasion_paradero_first = evasion_paradero[evasion_paradero['N_PUERTA']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in complete evasion database is: 96235\n",
      "Number of rows in evasion in paradero database is: 94531\n",
      "Number of rows in evasion in paradero by first door database is: 33755\n"
     ]
    }
   ],
   "source": [
    "print('Number of rows in complete evasion database is: ' + str(len(clean_processed_evasion.index)))\n",
    "print('Number of rows in evasion in paradero database is: ' + str(len(evasion_paradero.index)))\n",
    "print('Number of rows in evasion in paradero by first door database is: ' + str(len(evasion_paradero_first.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Filtering dates not in common dates. DataFrame \"common_dates_evasion\" will be the final evasion DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in complete evasion database filtered by common_dates is: 14756\n"
     ]
    }
   ],
   "source": [
    "common_dates = TransantiagoConstants.common_dates\n",
    "common_dates_timestamp = [pd.to_datetime(x) for x in common_dates]\n",
    "common_dates_evasion = evasion_paradero_first[evasion_paradero_first['FECHA'].isin(common_dates_timestamp)]\n",
    "\n",
    "print('Number of rows in complete evasion database filtered by common_dates is: ' + str(len(common_dates_evasion.index))) #Remember to store the number.\n",
    "\n",
    "common_dates_evasion.loc[:,'TIEMPO'] = common_dates_evasion.loc[:,'FECHA'].dt.strftime('%Y-%m-%d') + ' ' + common_dates_evasion.loc[:,'TIEMPO']\n",
    "common_dates_evasion.loc[:,'TIEMPO'] = pd.to_datetime(common_dates_evasion.loc[:,'TIEMPO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_dates_evasion = common_dates_evasion.sort_values(by=['PATENTE', 'SERVICIO', 'TIEMPO'], ascending=[True, True, True])\n",
    "common_dates_evasion = common_dates_evasion.reset_index(drop =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patentes = common_dates_evasion['PATENTE'].unique()\n",
    "patentes = patentes.tolist()\n",
    "servicios = common_dates_evasion['SERVICIO'].unique()\n",
    "servicios = servicios.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Building Etapas DataBase via RunSilentlyDailyEtapasBuilder"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#common_dates = common_dates[:1]\n",
    "common_dates = ['2017-04-11']"
=======
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_dates = common_dates[:3]"
>>>>>>> parent of b243e56... Fixex #8
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 16,
>>>>>>> parent of b243e56... Fixex #8
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from RunSilentlyDailyEtapasBuilder import RunSilentlyDailyEtapasBuilderClass"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": null,
>>>>>>> parent of b243e56... Fixex #8
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "import MatchingUsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not found in turnstile database: 1829611\n"
     ]
    }
   ],
   "source": [
    "for date in common_dates:    \n",
=======
    "for date in common_dates:\n",
    "    \n",
>>>>>>> parent of b243e56... Fixex #8
    "    etapas_builder = RunSilentlyDailyEtapasBuilderClass(date)\n",
    "    processed_sorted_df = etapas_builder.runProcessedProcess()\n",
    "#    processed_sorted_df = processed_sorted_df[processed_sorted_df['diferencia_tiempo_secs']<=20] <- BE AWARE OF THIS LINE...\n",
    "    processed_sorted_df['sitio_subida'] = processed_sorted_df['sitio_subida'].str.replace(\"-\", \"\")\n",
    "    processed_sorted_df['sitio_subida'] = processed_sorted_df['sitio_subida'].str.replace(\" \", \"\")\n",
    "    processed_sorted_df['servicio_subida'] =  processed_sorted_df['servicio_subida'].str.replace('T','')\n",
    "    processed_sorted_df['servicio_subida'] =  processed_sorted_df['servicio_subida'].str.split(' ').str[0]\n",
    "    clean_sorted_df = processed_sorted_df[(processed_sorted_df['sitio_subida'].isin(patentes))&(processed_sorted_df['servicio_subida'].isin(servicios))]\n",
    "    clean_sorted_df = clean_sorted_df.reset_index(drop=True)\n",
    "    \n",
    "    past_servicio = ''\n",
    "    past_patente = ''\n",
    "    past_time = pd.to_datetime('')\n",
    "    id_exp = 1\n",
    "    clean_sorted_df['idExpedicion'] = ''\n",
    "\n",
    "    # 1 - appending idExpedicion built ad-hoc #\n",
    "    for index,row in clean_sorted_df.iterrows():\n",
    "        actual_servicio = row['servicio_subida']\n",
    "        actual_patente = row['sitio_subida']\n",
    "        actual_time = row['t_subida']\n",
    "\n",
    "        #SOMETHING\n",
    "        if((past_servicio==actual_servicio)&(actual_time - past_time <= (pd.to_datetime('2017-04-11 00:15:00')-pd.to_datetime('2017-04-11 00:00:00')))):\n",
    "            clean_sorted_df.loc[index,'idExpedicion'] = id_exp\n",
    "\n",
    "        elif((past_servicio==actual_servicio)&(actual_time - past_time > (pd.to_datetime('2017-04-11 00:15:00')-pd.to_datetime('2017-04-11 00:00:00')))):\n",
    "            id_exp = id_exp + 1\n",
    "            clean_sorted_df.loc[index,'idExpedicion'] = id_exp\n",
    "\n",
    "        elif((past_servicio!=actual_servicio)):\n",
    "            id_exp = 1\n",
    "            clean_sorted_df.loc[index,'idExpedicion'] = id_exp\n",
    "\n",
    "\n",
    "        past_servicio = actual_servicio\n",
    "        past_patente = actual_patente\n",
    "        past_time = actual_time\n",
    "    \n",
    "    f = {'t_subida':['min', 'max', 'count'], 'diferencia_tiempo_secs':['mean']}\n",
    "    grouped_clean_sorted_df = clean_sorted_df.groupby(['sitio_subida','servicio_subida','idExpedicion','par_subida']).agg(f)\n",
    "    grouped_clean_sorted_df = grouped_clean_sorted_df.reset_index()\n",
    "    grouped_clean_sorted_df.columns = [''.join(col).strip() for col in grouped_clean_sorted_df.columns.values]\n",
    "    grouped_clean_sorted_df = grouped_clean_sorted_df.sort_values(by=['sitio_subida', 'servicio_subida', 'idExpedicion', 't_subidamin'], ascending=[True, True, True, True])\n",
    "    grouped_clean_sorted_df = grouped_clean_sorted_df.reset_index(drop=True)\n",
    "    \n",
<<<<<<< HEAD
    "    clean_sorted_df = MatchingUsers.appendingIdExpedicion(clean_sorted_df)\n",
    "    grouped_clean_sorted_df_1 = MatchingUsers.groupByEtapasDatabase(clean_sorted_df)    \n",
    "    grouped_clean_sorted_df_2 = MatchingUsers.appendingStartEndCuts(grouped_clean_sorted_df_1)\n",
    "    grouped_clean_sorted_df_3 = MatchingUsers.slicingEvasionDatabase(grouped_clean_sorted_df_2,evasion_by_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1106"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(evasion_by_date.index) #PASSED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11937"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_sorted_df.index) #PASSED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3994"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(grouped_clean_sorted_df_1) #PASSED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3994"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(grouped_clean_sorted_df_2) #PASSED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3994"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(grouped_clean_sorted_df_3) #PASSED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sitio_subida</th>\n",
       "      <th>servicio_subida</th>\n",
       "      <th>idExpedicion</th>\n",
       "      <th>par_subida</th>\n",
       "      <th>t_subidamin</th>\n",
       "      <th>t_subidamax</th>\n",
       "      <th>t_subidacount</th>\n",
       "      <th>diferencia_tiempo_secsmean</th>\n",
       "      <th>start_cut</th>\n",
       "      <th>end_cut</th>\n",
       "      <th>count_ev_obs</th>\n",
       "      <th>ingresan</th>\n",
       "      <th>no_validan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BJFB62</td>\n",
       "      <td>507</td>\n",
       "      <td>1</td>\n",
       "      <td>L-10-55-5-PO</td>\n",
       "      <td>2017-04-11 08:00:54</td>\n",
       "      <td>2017-04-11 08:00:54</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-04-11 08:00:24</td>\n",
       "      <td>2017-04-11 08:01:51.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BJFB62</td>\n",
       "      <td>507</td>\n",
       "      <td>1</td>\n",
       "      <td>L-10-82-5-PO</td>\n",
       "      <td>2017-04-11 08:02:49</td>\n",
       "      <td>2017-04-11 08:02:49</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-04-11 08:01:51.500000</td>\n",
       "      <td>2017-04-11 08:03:17.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BJFB62</td>\n",
       "      <td>507</td>\n",
       "      <td>1</td>\n",
       "      <td>L-10-37-20-NS</td>\n",
       "      <td>2017-04-11 08:03:46</td>\n",
       "      <td>2017-04-11 08:03:48</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2017-04-11 08:03:17.500000</td>\n",
       "      <td>2017-04-11 08:05:02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BJFB62</td>\n",
       "      <td>507</td>\n",
       "      <td>1</td>\n",
       "      <td>L-10-21-45-NS</td>\n",
       "      <td>2017-04-11 08:06:16</td>\n",
       "      <td>2017-04-11 08:06:16</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-04-11 08:05:02</td>\n",
       "      <td>2017-04-11 08:10:43.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BJFB62</td>\n",
       "      <td>507</td>\n",
       "      <td>1</td>\n",
       "      <td>T-10-455-SN-5</td>\n",
       "      <td>2017-04-11 08:15:11</td>\n",
       "      <td>2017-04-11 08:15:11</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-04-11 08:10:43.500000</td>\n",
       "      <td>2017-04-11 08:15:46.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sitio_subida servicio_subida  idExpedicion     par_subida  \\\n",
       "0       BJFB62             507             1   L-10-55-5-PO   \n",
       "1       BJFB62             507             1   L-10-82-5-PO   \n",
       "2       BJFB62             507             1  L-10-37-20-NS   \n",
       "3       BJFB62             507             1  L-10-21-45-NS   \n",
       "4       BJFB62             507             1  T-10-455-SN-5   \n",
       "\n",
       "          t_subidamin         t_subidamax  t_subidacount  \\\n",
       "0 2017-04-11 08:00:54 2017-04-11 08:00:54              1   \n",
       "1 2017-04-11 08:02:49 2017-04-11 08:02:49              1   \n",
       "2 2017-04-11 08:03:46 2017-04-11 08:03:48              2   \n",
       "3 2017-04-11 08:06:16 2017-04-11 08:06:16              1   \n",
       "4 2017-04-11 08:15:11 2017-04-11 08:15:11              1   \n",
       "\n",
       "   diferencia_tiempo_secsmean                   start_cut  \\\n",
       "0                         NaN         2017-04-11 08:00:24   \n",
       "1                         NaN  2017-04-11 08:01:51.500000   \n",
       "2                         2.0  2017-04-11 08:03:17.500000   \n",
       "3                         NaN         2017-04-11 08:05:02   \n",
       "4                         NaN  2017-04-11 08:10:43.500000   \n",
       "\n",
       "                      end_cut  count_ev_obs  ingresan  no_validan  \n",
       "0  2017-04-11 08:01:51.500000           0.0       0.0         0.0  \n",
       "1  2017-04-11 08:03:17.500000           0.0       0.0         0.0  \n",
       "2         2017-04-11 08:05:02           0.0       0.0         0.0  \n",
       "3  2017-04-11 08:10:43.500000           0.0       0.0         0.0  \n",
       "4  2017-04-11 08:15:46.500000           0.0       0.0         0.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_clean_sorted_df_3.head()"
=======
    "    past_plate = '-'\n",
    "    past_service = '-'\n",
    "    past_par_subida = ['']\n",
    "    past_initial_hour = pd.to_datetime('2017-04-11 00:00:00')\n",
    "    past_end_hour = pd.to_datetime('2017-04-11 00:00:00')\n",
    "    past_id_expedicion = '-'\n",
    "\n",
    "    grouped_clean_sorted_df['start_cut']=''\n",
    "    grouped_clean_sorted_df['end_cut']=''\n",
    "\n",
    "    for index,row in grouped_clean_sorted_df.iterrows():\n",
    "\n",
    "        future_index = index+1\n",
    "\n",
    "        actual_plate = row['sitio_subida']\n",
    "        actual_service = row['servicio_subida']\n",
    "        actual_initial_hour = row['t_subidamin']\n",
    "        actual_end_hour = row['t_subidamax']\n",
    "\n",
    "        actual_id_expedicion = row['idExpedicion']\n",
    "\n",
    "        if ((actual_plate!=past_plate)|(actual_service!=past_service)|(actual_id_expedicion!=past_id_expedicion)): #Assuming a pre-defined value, i.e., 30 seconds.\n",
    "            start_cut = actual_initial_hour - (pd.to_datetime('2017-04-11 00:01:00') - pd.to_datetime('2017-04-11 00:00:30'))\n",
    "        else:\n",
    "            start_cut = actual_initial_hour - (actual_initial_hour - past_end_hour)/2\n",
    "\n",
    "\n",
    "        if future_index >= len(grouped_clean_sorted_df.index): #We are at the end of the ddff. Assuming a pre-defined value, i.e., 30 seconds \n",
    "            end_cut = actual_end_hour + (pd.to_datetime('2017-04-11 00:01:00') - pd.to_datetime('2017-04-11 00:00:30'))\n",
    "\n",
    "        else:        \n",
    "            future_plate = grouped_clean_sorted_df.loc[future_index,'sitio_subida']\n",
    "            future_service = grouped_clean_sorted_df.loc[future_index,'servicio_subida']\n",
    "            future_initial_hour = grouped_clean_sorted_df.loc[future_index,'t_subidamin']\n",
    "            future_end_hour = grouped_clean_sorted_df.loc[future_index,'t_subidamax']\n",
    "            future_id_expedicion = grouped_clean_sorted_df.loc[future_index,'idExpedicion']\n",
    "\n",
    "            if ((actual_plate!=future_plate)|(actual_service!=future_service)|(actual_id_expedicion!=future_id_expedicion)): #Changing service or plate... assuming a pre-defined value, i.e., 30 seconds\n",
    "                end_cut = actual_end_hour + (pd.to_datetime('2017-04-11 00:01:00') - pd.to_datetime('2017-04-11 00:00:30'))\n",
    "            else:\n",
    "                end_cut = actual_end_hour + (future_initial_hour - actual_end_hour)/2\n",
    "\n",
    "        past_initial_hour = actual_initial_hour\n",
    "        past_end_hour = actual_end_hour\n",
    "        past_id_expedicion = actual_id_expedicion\n",
    "        past_plate = actual_plate\n",
    "        past_service = actual_service\n",
    "        grouped_clean_sorted_df.loc[index,'start_cut']=start_cut\n",
    "        grouped_clean_sorted_df.loc[index,'end_cut']=end_cut\n",
    "\n",
    "    for index,row in grouped_clean_sorted_df.iterrows():\n",
    "        actual_plate = row['sitio_subida']\n",
    "        actual_service = row['servicio_subida']\n",
    "        start_cut = row['start_cut']\n",
    "        end_cut = row['end_cut']\n",
    "\n",
    "        actual_util_df = example[(example['PATENTE']==actual_plate)&(example['SERVICIO']==actual_service)&(start_cut<=example['TIEMPO'])&(example['TIEMPO']<=end_cut)]\n",
    "        actual_util_df = actual_util_df[(actual_util_df['INGRESAN'] > actual_util_df['NO_VALIDAN'])] #Be aware of this condition\n",
    "        actual_ev_obs = len(actual_util_df.index) #Mantains order of appearence\n",
    "\n",
    "        grouped_clean_sorted_df.loc[index,'count_ev_obs'] = actual_ev_obs\n",
    "        grouped_clean_sorted_df.loc[index,'ingresan'] = actual_util_df['INGRESAN'].sum()\n",
    "        grouped_clean_sorted_df.loc[index,'no_validan'] = actual_util_df['NO_VALIDAN'].sum()"
>>>>>>> parent of b243e56... Fixex #8
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
