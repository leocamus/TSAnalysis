{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Matching Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "import datetime as dt\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "from Utils import TransantiagoConstants\n",
    "\n",
    "first_quarter_path = \"C:/Users/leoca_000/Desktop/Evasion/01_analisis/03_datos/06_RFA/01_EvasionTrimestral/01_analisis/1st_quarter.xlsx\"\n",
    "second_quarter_path = \"C:/Users/leoca_000/Desktop/Evasion/01_analisis/03_datos/06_RFA/01_EvasionTrimestral/01_analisis/2nd_quarter.xlsx\"\n",
    "third_quarter_path = \"C:/Users/leoca_000/Desktop/Evasion/01_analisis/03_datos/06_RFA/01_EvasionTrimestral/01_analisis/3rd_quarter.xlsx\"\n",
    "codes_path = \"C:/Users/leoca_000/Desktop/Evasion/01_analisis/03_datos/04_DTPM/codes_services.xlsx\"\n",
    "\n",
    "first_quarter_evasion = pd.read_excel(first_quarter_path, encoding = 'latin-1')\n",
    "second_quarter_evasion = pd.read_excel(second_quarter_path, encoding = 'latin-1')\n",
    "third_quarter_evasion = pd.read_excel(third_quarter_path, encoding = 'latin-1')\n",
    "codes = pd.read_excel(codes_path, encoding = 'latin-1')\n",
    "\n",
    "first_quarter_evasion['TIEMPO'] = first_quarter_evasion['HORA'].astype(str)+':'+first_quarter_evasion['MINUTOS'].astype(str)+':00'\n",
    "second_quarter_evasion['TIEMPO'] = second_quarter_evasion['HORA'].astype(str)+':'+second_quarter_evasion['MINUTOS'].astype(str)+':00'\n",
    "third_quarter_evasion['TIEMPO'] = third_quarter_evasion['HORA'].astype(str)+':'+third_quarter_evasion['MINUTOS'].astype(str)+':00'\n",
    "\n",
    "first_quarter_evasion.columns = ['FECHA', 'SERVICIO','PATENTE','PUERTAS','N_PUERTA','LUGAR_INICIO','HORA_INICIO','HORA','MINUTO','INGRESAN','NO_VALIDAN','TP','TIEMPO']\n",
    "second_quarter_evasion.columns = ['FECHA', 'SERVICIO','TIPO','PATENTE','PUERTAS','N_PUERTA','LUGAR_INICIO','HORA_INICIO','HORA','MINUTO','INGRESAN','NO_VALIDAN','TP','TIEMPO']\n",
    "third_quarter_evasion.columns = ['FECHA', 'SERVICIO','PATENTE','PUERTAS','N_PUERTA','LUGAR_INICIO','HORA_INICIO','HORA','MINUTO','INGRESAN','NO_VALIDAN','TP','TIEMPO']\n",
    "del second_quarter_evasion['TIPO']\n",
    "\n",
    "#Processing codes before merging.\n",
    "\n",
    "codes_ida = codes[codes['DIRECTION']=='Ida']\n",
    "codes_ret = codes[codes['DIRECTION']=='Ret']\n",
    "\n",
    "codes_ida = codes_ida.rename(columns = {'USER_CODE':'SERVICIO'})\n",
    "codes_ret = codes_ret.rename(columns = {'USER_CODE':'SERVICIO'})\n",
    "\n",
    "del codes_ida['DIRECTION']\n",
    "del codes_ret['DIRECTION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(type(first_quarter_evasion.loc[0,'TIEMPO'])) #should be a string\n",
    "print(type(first_quarter_evasion.loc[0,'FECHA'])) #should be a timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frames = [first_quarter_evasion, second_quarter_evasion, third_quarter_evasion]\n",
    "evasion = pd.concat(frames, keys=['first', 'second', 'third'])\n",
    "del evasion['LUGAR_INICIO']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Merge should be made only by codes_ida or codes_ret. Be aware of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evasion = pd.merge(evasion,codes_ida, on=['SERVICIO'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(evasion.loc[evasion['TS_CODE'].isnull(),'SERVICIO'].unique()) #should be only D06, so the line below makes sense. Anyway, it is hardcoded so be aware.\n",
    "evasion.loc[evasion['TS_CODE'].isnull(),'TS_CODE']='446'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Processing evasion-ddbb before merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evasion['PATENTE'] =  evasion['PATENTE'].str.replace(' ','')\n",
    "\n",
    "evasion['SERVICIO_TMP'] = evasion['SERVICIO'].apply(str)\n",
    "evasion['TS_CODE_TMP'] = evasion['TS_CODE'].apply(str)\n",
    "\n",
    "del evasion['SERVICIO']\n",
    "del evasion['TS_CODE']\n",
    "\n",
    "evasion = evasion.rename(columns = {'SERVICIO_TMP':'SERVICIO_USUARIO', 'TS_CODE_TMP':'SERVICIO'})\n",
    "evasion_paradero = evasion[evasion['TP']=='P']\n",
    "evasion_paradero_first = evasion_paradero[evasion_paradero['N_PUERTA']==1]\n",
    "print(type(evasion['SERVICIO'][0])) #should be a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of rows in complete evasion database is: ' + str(len(evasion.index)))\n",
    "print('Number of rows in evasion in paradero database is: ' + str(len(evasion_paradero.index)))\n",
    "print('Number of rows in evasion in paradero by first door database is: ' + str(len(evasion_paradero_first.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Getting rid of duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Getting duplicated rows\n",
    "duplicated_evasion_paradero_first = evasion_paradero_first[evasion_paradero_first.duplicated(['FECHA','PATENTE','PUERTAS','N_PUERTA','HORA_INICIO','HORA','MINUTO','TP','TIEMPO','UN','SERVICIO_USUARIO','SERVICIO'], keep=False)]\n",
    "print('Number of duplicated rows in evasion in paradero by first door database is: ' + str(len(duplicated_evasion_paradero_first.index)))\n",
    "\n",
    "#Colapsing duplicated rows\n",
    "grouped_temporal_evasion_paradero_first = duplicated_evasion_paradero_first.groupby(['FECHA','PATENTE','PUERTAS','N_PUERTA','HORA_INICIO','HORA','MINUTO','TP','TIEMPO','UN','SERVICIO_USUARIO','SERVICIO'])['INGRESAN','NO_VALIDAN'].sum()\n",
    "grouped_temporal_evasion_paradero_first = grouped_temporal_evasion_paradero_first.reset_index()\n",
    "print('Number of collapsed-duplicated rows in evasion in paradero by first door database is: ' + str(len(grouped_temporal_evasion_paradero_first.index)))\n",
    "\n",
    "#Deleting duplicated rows in evasion in paradero by first door database\n",
    "non_duplicated_evasion_paradero_first = evasion_paradero_first.drop_duplicates(['FECHA','PATENTE','PUERTAS','N_PUERTA','HORA_INICIO','HORA','MINUTO','TP','TIEMPO','UN','SERVICIO_USUARIO','SERVICIO'], keep=False)\n",
    "print('Number of rows in evasion in paradero by first door without duplicated rows at all is: ' + str(len(non_duplicated_evasion_paradero_first.index)))\n",
    "\n",
    "#Appendind\n",
    "del evasion_paradero_first\n",
    "frames = [non_duplicated_evasion_paradero_first, grouped_temporal_evasion_paradero_first]\n",
    "evasion_paradero_first = pd.concat(frames)\n",
    "print('Final number of rows in evasion in paradero by first door with collapsed duplicated rows is: ' + str(len(evasion_paradero_first.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Filtering dates not in common dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_dates = TransantiagoConstants.common_dates\n",
    "common_dates_timestamp = [pd.to_datetime(x) for x in common_dates]\n",
    "common_dates_evasion = evasion_paradero_first[evasion_paradero_first['FECHA'].isin(common_dates_timestamp)]\n",
    "len(common_dates_evasion.index) #Remember to store the number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>Filtering for one specific common date and analyze it to refactor and debug <- this part should be omitted in the final script. Above methodology is general</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example = common_dates_evasion[common_dates_evasion['FECHA']==pd.to_datetime('2017-04-11')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(example.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from RunSilentlyDailyEtapasBuilder import RunSilentlyDailyEtapasBuilderClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '2017-04-11'\n",
    "etapas_builder = RunSilentlyDailyEtapasBuilderClass(date)\n",
    "sorted_df = etapas_builder.runRawProcess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sorted_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Processing sorted_df before reducing complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_df['servicio_subida'] =  sorted_df['servicio_subida'].str.replace('T','')\n",
    "sorted_df['servicio_subida'] =  sorted_df['servicio_subida'].str.split(' ').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_df['sitio_subida'] = sorted_df['sitio_subida'].str.replace(\"-\", \"\")\n",
    "sorted_df['sitio_subida'] = sorted_df['sitio_subida'].str.replace(\" \", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* First: filter etapas by patentes and servicios surveyed in evasion ddbb so to reduce search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patentes = example['PATENTE'].unique()\n",
    "patentes = patentes.tolist()\n",
    "servicios = example['SERVICIO'].unique()\n",
    "servicios = servicios.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_sorted_df = sorted_df[(sorted_df['sitio_subida'].isin(patentes))&(sorted_df['servicio_subida'].isin(servicios))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clean_sorted_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Evasion should be sorted first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example['TIEMPO'] = example['FECHA'].dt.strftime('%Y-%m-%d') + ' ' + example['TIEMPO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example['TIEMPO'] = pd.to_datetime(example['TIEMPO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example = example.sort_values(by=['PATENTE', 'SERVICIO', 'TIEMPO'], ascending=[True, True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example = example.reset_index(drop =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "example.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_sorted_df[(clean_sorted_df['sitio_subida']=='BJFB62')&(clean_sorted_df['servicio_subida']=='507')&(clean_sorted_df['t_subida']>=pd.to_datetime('2017-04-11 15:08:00'))].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_sorted_df = clean_sorted_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_sorted_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* New Methodology: this methodology is based on appending PARADEROS to evasion ddbb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "past_plate = '-'\n",
    "past_service = '-'\n",
    "\n",
    "example['start_cut']=''\n",
    "example['end_cut']=''\n",
    "example['paradero']=''\n",
    "past_util_df = pd.DataFrame()\n",
    "past_par_subida = ['']\n",
    "from IPython.core.debugger import Tracer\n",
    "\n",
    "for index,row in example.iterrows():\n",
    "    future_index = index+1\n",
    "    actual_plate = row['PATENTE']\n",
    "    actual_service = row['SERVICIO']\n",
    "    actual_hour = row['TIEMPO']\n",
    "    \n",
    "    if (actual_plate!=past_plate)|(actual_service!=past_service):\n",
    "        past_hour = pd.to_datetime('2017-04-11 00:00:00') #Starting hour <- consider to change this\n",
    "        \n",
    "    if past_hour == pd.to_datetime('2017-04-11 00:00:00'): #Assuming a pre-defined value, i.e., 1 minute.\n",
    "        start_cut = actual_hour - (pd.to_datetime('2017-04-11 00:02:00') - pd.to_datetime('2017-04-11 00:01:00'))\n",
    "    else:\n",
    "        start_cut = actual_hour - (actual_hour - past_hour)/2\n",
    "    \n",
    "    if future_index >= len(example.index): #We are at the end of the ddff. Assuming a pre-defined value, i.e., 1 minute.\n",
    "        end_cut = actual_hour + (pd.to_datetime('2017-04-11 00:02:00') - pd.to_datetime('2017-04-11 00:01:00'))\n",
    "    else:\n",
    "        future_hour = example.loc[future_index,'TIEMPO']\n",
    "        end_cut = actual_hour + (future_hour - actual_hour)/2\n",
    "        \n",
    "    actual_util_df = clean_sorted_df[(clean_sorted_df['sitio_subida']==actual_plate)&(clean_sorted_df['servicio_subida']==actual_service)&(start_cut<=clean_sorted_df['t_subida'])&(clean_sorted_df['t_subida']<=end_cut)]\n",
    "    actual_par_subida = actual_util_df['par_subida'].unique().tolist()\n",
    "    \n",
    "    if len(actual_par_subida)<1: \n",
    "        #Aqui hay dos situaciones: \n",
    "        #1. Las trx no alcanzan a estar dentro del rango\n",
    "        #2. Simplemente hay anotaciones extrañas.\n",
    "        #First: agrandar el rango de busqueda por 30 segundos...\n",
    "        start_cut = start_cut - (pd.to_datetime('2017-04-11 00:01:30') - pd.to_datetime('2017-04-11 00:01:00'))\n",
    "        end_cut = end_cut + (pd.to_datetime('2017-04-11 00:01:30') - pd.to_datetime('2017-04-11 00:01:00'))\n",
    "        actual_util_df = clean_sorted_df[(clean_sorted_df['sitio_subida']==actual_plate)&(clean_sorted_df['servicio_subida']==actual_service)&(start_cut<=clean_sorted_df['t_subida'])&(clean_sorted_df['t_subida']<=end_cut)]\n",
    "        actual_par_subida = actual_util_df['par_subida'].unique().tolist()\n",
    "        #Si agrandar el rango de busqueda no funciona... entonces asignar el anteriormente visitado.\n",
    "        if len(actual_par_subida)<1:\n",
    "            actual_par_subida = past_par_subida\n",
    "            example.loc[index,'paradero']=actual_par_subida[len(actual_par_subida)-1] #Esto es asignar el último visitado (ad-hoc)\n",
    "        #Si agrandar el rango de busqueda funciona, entonces asignar el paradero que se encontró\n",
    "        else:\n",
    "            example.loc[index,'paradero']=actual_par_subida[0]\n",
    "            past_par_subida = actual_par_subida\n",
    "    \n",
    "    elif len(actual_par_subida)==1:\n",
    "        #Si se encontró un sólo paradero, entonces asignar (solución más sensata)\n",
    "        example.loc[index,'paradero']=actual_par_subida[0]\n",
    "        past_par_subida = actual_par_subida\n",
    "    \n",
    "    elif (len(actual_par_subida)>1):\n",
    "        #Si se observa más de un paradero...\n",
    "        if (past_par_subida[(len(past_par_subida)-1)]==actual_par_subida[0]):\n",
    "            #Si el último paradero de la iteración anterior coincide con el primer paradero de la iteración actual\n",
    "            example.loc[index,'paradero']=actual_par_subida[1] #Asignar el siguiente paradero en la lista.\n",
    "            past_par_subida = actual_par_subida[1]\n",
    "        else: \n",
    "            #Si no coinciden... asignar el primero\n",
    "            example.loc[index,'paradero']=actual_par_subida[0] #Asignar el primero.\n",
    "            past_par_subida = actual_par_subida[0]\n",
    "        \n",
    "#    if index>=11:\n",
    "#        Tracer()()\n",
    "    example.loc[index,'start_cut']=start_cut\n",
    "    example.loc[index,'end_cut']=end_cut\n",
    "    past_plate = actual_plate\n",
    "    past_service = actual_service\n",
    "    past_hour = actual_hour\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "example.loc[8:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_sorted_df.loc[60:85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_subida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Old Methodology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "past_plate = '-'\n",
    "past_service = '-'\n",
    "\n",
    "example['total_delta']=''\n",
    "example['mean_delta']=''\n",
    "example['count_delta']=''\n",
    "example['start_cut']=''\n",
    "example['end_cut']=''\n",
    "\n",
    "for index,row in example.iterrows():\n",
    "    future_index = index+1\n",
    "    actual_plate = row['PATENTE']\n",
    "    actual_service = row['SERVICIO']\n",
    "    actual_hour = row['TIEMPO']\n",
    "    \n",
    "    if (actual_plate!=past_plate)|(actual_service!=past_service):\n",
    "        past_hour = pd.to_datetime('2017-04-11 00:00:00') #Starting hour <- consider to change this\n",
    "        \n",
    "    if past_hour == pd.to_datetime('2017-04-11 00:00:00'): #Assuming a pre-defined value, i.e., 1 minute.\n",
    "        start_cut = actual_hour - (pd.to_datetime('2017-04-11 00:02:00') - pd.to_datetime('2017-04-11 00:01:00'))\n",
    "    else:\n",
    "        start_cut = actual_hour - (actual_hour - past_hour)/2\n",
    "    \n",
    "    if future_index >= len(example.index): #We are at the end of the ddff. Assuming a pre-defined value, i.e., 1 minute.\n",
    "        end_cut = actual_hour + (pd.to_datetime('2017-04-11 00:02:00') - pd.to_datetime('2017-04-11 00:01:00'))\n",
    "    else:\n",
    "        future_hour = example.loc[future_index,'TIEMPO']\n",
    "        end_cut = actual_hour + (future_hour - actual_hour)/2  \n",
    "\n",
    "    util_df = clean_filtered_df[(clean_filtered_df['sitio_subida']==actual_plate)&(clean_filtered_df['servicio_subida']==actual_service)&((start_cut<=clean_filtered_df['t_subida'])&(clean_filtered_df['t_subida']<=end_cut))]\n",
    "    util_df_indexes = util_df.index.values\n",
    "    number_of_indexes = len(util_df_indexes)\n",
    "    \n",
    "    first_util_df_index = util_df_indexes[0]\n",
    "    last_util_df_index = util_df_indexes[number_of_indexes-1]\n",
    "    #Checking up of util_df --- until a condition is reached\n",
    "    j=1\n",
    "    while True:\n",
    "        upper_util_row = clean_filtered_df.loc(first_util_df_index-j)\n",
    "        if upper_util_row['par_subida'] == util_df['par_subida']: #Si el paradero de subida de la fila inmediatamente anterior al util_df es el mismo, then append it and continue < the issue here es que hay que sacarlo del util_df anteriormente analizado...\n",
    "            util_df.concat[upper_util_row]\n",
    "            j=j+1\n",
    "        else \n",
    "    \n",
    "    \n",
    "    total_delta = util_df['diferencia_tiempo_secs'].sum()\n",
    "    mean_delta = util_df['diferencia_tiempo_secs'].mean()\n",
    "    count_delta = util_df['diferencia_tiempo_secs'].count() \n",
    "    \n",
    "    example.loc[index,'total_delta'] = total_delta\n",
    "    example.loc[index,'mean_delta'] = mean_delta\n",
    "    example.loc[index,'count_delta'] = count_delta\n",
    "    example.loc[index,'start_cut']=start_cut\n",
    "    example.loc[index,'end_cut']=end_cut\n",
    "    \n",
    "    past_plate = actual_plate\n",
    "    past_service = actual_service\n",
    "    past_hour = actual_hour\n",
    "    \n",
    "    i=i+1\n",
    "#    if (actual_plate == 'ZN6539')&(actual_service=='109'):\n",
    "#        print(i)\n",
    "#        print(start_cut)\n",
    "#        print(end_cut)\n",
    "\n",
    "#        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST OLD METHODOLOGY (Check issue #8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Above table shows:\n",
    "- PATENTE == BJFB62 & TIEMPO == 2017-04-11 15:10:00 & SERVICIO == 507 > sum = 08, mean = 2.66667, count = 3 > check them in clean_filtered_df.loc[182369:182380] > <font color='green'>Test passed</font>\n",
    "- PATENTE == BJFB62 & TIEMPO == 2017-04-11 15:32:00 & SERVICIO == 507 > sum = 13, mean = 6.50000, count = 2 > check them in clean_filtered_df.loc[182388:182395] > <font color='green'>Test passed, although incorrectly assignment</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_filtered_df.loc[182369:182380]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_filtered_df.loc[182388:182395]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "example.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Above table shows:\n",
    "- PATENTE == ZN6539 & TIEMPO == 2017-04-11 14:31:00 & SERVICIO == 109 > sum = 08, mean = 04, count = 02 > check them in clean_filtered_df.loc[2527175:2527180] > <font color='green'>Test passed</font>\n",
    "- PATENTE == ZN6539\t& TIEMPO == 2017-04-11 14:37:00 & SERVICIO == 109 > sum = 21, mean = 21, count = 01 > check them in clean_filtered_df.loc[2527178:2527187] > <font color='green'>Test passed</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_filtered_df.loc[2527175:2527180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_filtered_df.loc[2527178:2527187]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "util_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_indexes = util_df.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "length = len(df_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_indexes[length-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
